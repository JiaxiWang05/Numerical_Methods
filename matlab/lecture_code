
This MATLAB code demonstrates the calculation of numerical derivatives using three different methods: **forward difference**, **backward difference**, and **central difference**. The calculations are performed for a cosine function at \( x = \frac{\pi}{6} \) with varying step sizes \( h \), and the errors are computed by comparing the results to the exact derivative value of the cosine function at \( x = \frac{\pi}{6} \), which is \(-0.5\).

Here's a detailed line-by-line explanation:

---

### **1. Comments**
The comments at the top of the script provide basic information:
- **Purpose**: The code is part of Lecture 2, showing numerical differentiation.
- **Author**: Stefano Giani.
- **Date**: The code was created on October 8, 2019.

### **2. Display Format**
```matlab
format shorteng
```
- Sets the display format for numerical values in the MATLAB command window to **short engineering notation**, which uses powers of 10. This makes large or small numbers easier to read.

---

### **3. Step Sizes**
```matlab
h = 0.1 ./ 2.^(0:5);
```
- **Step Size Definition**:
  - Creates a vector \( h \) of step sizes for numerical differentiation: \([0.1, 0.05, 0.025, 0.0125, 0.00625, 0.003125]\).
  - \( h \) is generated by dividing \( 0.1 \) by powers of 2 (\( 2^0, 2^1, \dots, 2^5 \)).
- These values determine the intervals for finite difference approximations.

---

### **4. Initialize Vectors**
```matlab
gradf = zeros(6,1);
gradb = zeros(6,1);
gradc = zeros(6,1);
```
- **Preallocation**:
  - Creates three column vectors of zeros with 6 rows each to store the approximated gradients computed by the forward, backward, and central difference methods.
  - Preallocating memory improves computational efficiency in MATLAB.

---

### **5. Loop for Numerical Differentiation**
```matlab
for i=1:6
    gradf(i) = forward_diff( @cos, pi/6, h(i) );
    gradb(i) = backward_diff( @cos, pi/6, h(i) );
    gradc(i) = central_diff( @cos, pi/6, h(i) );
end
```
- **Purpose**:
  - Iterates through the six step sizes in \( h \).
  - Computes the numerical derivative for the cosine function \( \cos(x) \) at \( x = \pi/6 \) using the three methods: forward difference, backward difference, and central difference.

- **Functions Used**:
  - `forward_diff`: Computes the derivative using the forward difference formula:
    \[
    f'(x) \approx \frac{f(x+h) - f(x)}{h}
    \]
  - `backward_diff`: Computes the derivative using the backward difference formula:
    \[
    f'(x) \approx \frac{f(x) - f(x-h)}{h}
    \]
  - `central_diff`: Computes the derivative using the central difference formula:
    \[
    f'(x) \approx \frac{f(x+h) - f(x-h)}{2h}
    \]

- **Key Points**:
  - The step size \( h(i) \) varies to observe how accuracy changes as \( h \) decreases.
  - The function handle `@cos` passes the cosine function as an argument to the differentiation functions.

---

### **6. Compute Errors**
```matlab
errf = abs(-0.5 - gradf);
errb = abs(-0.5 - gradb);
errc = abs(-0.5 - gradc);
```
- **Exact Derivative**:
  - The exact derivative of \( \cos(x) \) at \( x = \pi/6 \) is \( -0.5 \) (since \( \sin(\pi/6) = 0.5 \)).
- **Error Calculation**:
  - The absolute error is computed for each method by subtracting the approximated derivative from the exact derivative (\(-0.5\)).
  - \( \text{Error} = | \text{Exact Value} - \text{Approximated Value} | \).

---

### **7. Create Results Table**
```matlab
T = table(h', gradf, errf, gradb, errb, gradc, errc);
T
```
- **Purpose**:
  - Constructs a table summarizing the results for step sizes \( h \), gradients, and errors for all three methods.
  - Columns in the table:
    1. \( h \): Step sizes.
    2. `gradf`: Gradients computed using forward difference.
    3. `errf`: Errors for forward difference.
    4. `gradb`: Gradients computed using backward difference.
    5. `errb`: Errors for backward difference.
    6. `gradc`: Gradients computed using central difference.
    7. `errc`: Errors for central difference.

- **Key Point**:
  - The table makes it easy to compare the accuracy of the three methods and observe how error decreases as \( h \) becomes smaller.

---

### **What This Code Demonstrates**
1. **Numerical Differentiation**:
   - Demonstrates the implementation of three finite difference methods for approximating derivatives.
   - Highlights differences in accuracy between the methods:
     - **Central Difference** is generally more accurate because it uses information from both sides of the point of interest.

2. **Impact of Step Size**:
   - Shows how decreasing the step size \( h \) improves the accuracy of the approximations, up to a point where round-off errors from floating-point arithmetic may dominate.

3. **Error Analysis**:
   - Provides insights into how numerical methods deviate from the exact solution due to truncation and rounding errors.

---

If you have further questions or need specific details about any part of the code, feel free to ask!
